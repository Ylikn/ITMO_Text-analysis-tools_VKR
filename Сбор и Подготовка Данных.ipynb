{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "\n",
    "import pymorphy2\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docx_paragraph_texts(document):\n",
    "    lst_lines = []\n",
    "    dict_paragraphs_texts = {}\n",
    "    for line, p in enumerate(document.paragraphs()):\n",
    "        p.paragraph_format\n",
    "        text_line = p.text.replace('\\n', ' ').strip()\n",
    "        if len(text_line) > 0:\n",
    "            text_line= text_line + '.'\n",
    "            text_line = text_line.strip().lstrip().rstrip().replace(\"..\", \".\").replace(\"\t\", \" \").replace(\" .\", \".\")\n",
    "        lst_lines.append(\"Paragraph {}: \".format(line)+text_line)\n",
    "        dict_paragraphs_texts[line] = text_line\n",
    "    return lst_lines, dict_paragraphs_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docx_sections_texts(document):\n",
    "    dict_sections_texts = {}\n",
    "    paragraphs = document.paragraphs\n",
    "    section_name = paragraphs[0].text\n",
    "    dict_sections_texts[section_name] = []\n",
    "    n = 1\n",
    "    for line, p in enumerate(paragraphs[1:]):\n",
    "        section_alignment = str(p.paragraph_format.alignment).split()[0] \n",
    "        section_text = p.text\n",
    "        #print(n, section_alignment, section_text)\n",
    "        if section_alignment == 'CENTER':\n",
    "            section_name = section_text\n",
    "            dict_sections_texts[section_name] = []\n",
    "\n",
    "        elif section_alignment != 'CENTER':\n",
    "            dict_sections_texts[section_name].append(section_text)\n",
    "            \n",
    "        n = n+1\n",
    "    return dict_sections_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_docs = \"/Users/ulananazarenko/Desktop/Диплом/ВКР_2020/\"\n",
    "lst_paths_files = []\n",
    "for root, dirs, files in os.walk(path_docs):\n",
    "    for name in files:\n",
    "        path_file = os.path.join(root, name)\n",
    "        lst_paths_files.append(path_file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list_files = os.listdir(path_docs)\n",
    "print('Количество документов:', len(list_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-87ff51954782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mpaper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparagraphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlst_papers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/docx/api.py\u001b[0m in \u001b[0;36mDocument\u001b[0;34m(docx)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \"\"\"\n\u001b[1;32m     24\u001b[0m     \u001b[0mdocx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_docx_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdocx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdocument_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_document_part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdocument_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWML_DOCUMENT_MAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtmpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"file '%s' is not a Word file, content type is '%s'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/docx/opc/package.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, pkg_file)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mpkg_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mpackage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mUnmarshaller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmarshal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPartFactory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/docx/opc/pkgreader.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(pkg_file)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m|\u001b[0m\u001b[0mPackageReader\u001b[0m\u001b[0;34m|\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mphys_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhysPkgReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mcontent_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ContentTypeMap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_types_xml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpkg_srels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_srels_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPACKAGE_URI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/docx/opc/phys_pkg.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pkg_file)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ZipPkgReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zipf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mblob_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpack_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "lst_dict_sections_texts = []\n",
    "lst_papers = []\n",
    "lst_paths_docs = []\n",
    "for path_file in lst_paths_files:\n",
    "    path_file = path_file.replace('\\\\', '/')\n",
    "    #print(path_file)\n",
    "    #try:\n",
    "    f = open(path_file, 'rb')\n",
    "    document = Document(f)\n",
    "    paper = [p.text for p in document.paragraphs]\n",
    "    lst_papers.append(paper)\n",
    "    \n",
    "    lst_dict_sections_texts.append(get_docx_sections_texts(document))\n",
    "    lst_paths_docs.append(path_file)\n",
    "    #print('\\n')\n",
    "    #except:\n",
    "     #   print(\"ERROR:\", path_file)\n",
    "      #  print('\\n')\n",
    "       # continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_doc</th>\n",
       "      <th>title</th>\n",
       "      <th>text_paper</th>\n",
       "      <th>dict_sections_texts</th>\n",
       "      <th>faculty_department</th>\n",
       "      <th>faculty</th>\n",
       "      <th>department</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [path_doc, title, text_paper, dict_sections_texts, faculty_department, faculty, department, degree]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_docs = pd.DataFrame()\n",
    "df_docs['path_doc'] = lst_paths_docs\n",
    "df_docs['title'] = df_docs['path_doc'].apply(lambda x: x.split('/')[-1])\n",
    "df_docs['text_paper'] = lst_papers\n",
    "\n",
    "df_docs['dict_sections_texts'] = lst_dict_sections_texts\n",
    "\n",
    "df_docs['faculty_department'] = df_docs['path_doc'].apply(lambda x: x.replace(path_docs, '').split('/')[:-1])\n",
    "df_docs['faculty'] = df_docs['faculty_department'].apply(lambda x: x[0])\n",
    "df_docs['department'] = df_docs['faculty_department'].apply(lambda x: x[1] if len(x)>1 else x[0])\n",
    "\n",
    "df_docs['degree'] = ['bachelor' for _ in range(len(df_docs))]\n",
    "print(len(df_docs))\n",
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_doc</th>\n",
       "      <th>title</th>\n",
       "      <th>text_paper</th>\n",
       "      <th>dict_sections_texts</th>\n",
       "      <th>faculty_department</th>\n",
       "      <th>faculty</th>\n",
       "      <th>department</th>\n",
       "      <th>degree</th>\n",
       "      <th>dict_sections_texts_clean</th>\n",
       "      <th>main_clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [path_doc, title, text_paper, dict_sections_texts, faculty_department, faculty, department, degree, dict_sections_texts_clean, main_clean_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def simple_dict_sections_texts_cleaning(dict_sections_texts):\n",
    "    dict_sections_texts_new = {}\n",
    "    for section, texts in dict_sections_texts.items():\n",
    "        if len(texts) == 0:\n",
    "            continue\n",
    "        section = section.lower().replace('\\t', ' ').replace('\\n', ' ').replace('  ', ' ').strip()\n",
    "        section = ''.join([ch for ch in section if ch not in string.punctuation])\n",
    "        dict_sections_texts_new[section] = []\n",
    "        for text in texts:\n",
    "            text = text.replace('\\t', ' ').replace('\\n', ' ').replace('  ', ' ').strip()\n",
    "            if text != '':\n",
    "                dict_sections_texts_new[section].append(text)\n",
    "        if len(dict_sections_texts_new[section]) == 0:\n",
    "            dict_sections_texts_new.pop(section)\n",
    "    return dict_sections_texts_new\n",
    "\n",
    "\n",
    "def get_main_clean_text(dict_sections_texts):\n",
    "    lst_texts = []\n",
    "    for section, lst in dict_sections_texts.items():\n",
    "        if len(lst)>0:\n",
    "            lst_texts = lst_texts+lst\n",
    "    return lst_texts\n",
    "\n",
    "\n",
    "df_docs['dict_sections_texts_clean'] = df_docs['dict_sections_texts'].map(simple_dict_sections_texts_cleaning)\n",
    "df_docs['main_clean_text'] = df_docs['dict_sections_texts_clean'].map(get_main_clean_text)\n",
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_doc</th>\n",
       "      <th>title</th>\n",
       "      <th>text_paper</th>\n",
       "      <th>dict_sections_texts</th>\n",
       "      <th>faculty_department</th>\n",
       "      <th>faculty</th>\n",
       "      <th>department</th>\n",
       "      <th>degree</th>\n",
       "      <th>dict_sections_texts_clean</th>\n",
       "      <th>main_clean_text</th>\n",
       "      <th>preproc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/JM 505 Computers/Desktop/Repetitor/Ул...</td>\n",
       "      <td>Анализ методов обеспечения безопасной передачи...</td>\n",
       "      <td>[ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА, АНАЛИЗ МЕТ...</td>\n",
       "      <td>{'ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА': [], 'АНА...</td>\n",
       "      <td>[ФБИТ]</td>\n",
       "      <td>ФБИТ</td>\n",
       "      <td>ФБИТ</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>{'анализ методов обеспечения безопасной переда...</td>\n",
       "      <td>[Автор Павлов Денис Дмитриевич, (Фамилия, Имя,...</td>\n",
       "      <td>[автор павлов денис дмитриевич, фамилия имя от...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/JM 505 Computers/Desktop/Repetitor/Ул...</td>\n",
       "      <td>Анализ психологических типов сотрудников для м...</td>\n",
       "      <td>[Министерство науки и высшего образования Росс...</td>\n",
       "      <td>{'Министерство науки и высшего образования Рос...</td>\n",
       "      <td>[ФБИТ]</td>\n",
       "      <td>ФБИТ</td>\n",
       "      <td>ФБИТ</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>{'министерство науки и высшего образования рос...</td>\n",
       "      <td>[ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ АВТОНОМНОЕ ОБРАЗО...</td>\n",
       "      <td>[федеральный государственный автономный образо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/JM 505 Computers/Desktop/Repetitor/Ул...</td>\n",
       "      <td>Исследование влияния алгоритма стохастического...</td>\n",
       "      <td>[Министерство науки и высшего образования Росс...</td>\n",
       "      <td>{'Министерство науки и высшего образования Рос...</td>\n",
       "      <td>[ФБИТ]</td>\n",
       "      <td>ФБИТ</td>\n",
       "      <td>ФБИТ</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>{'исследование влияния алгоритма стохастическо...</td>\n",
       "      <td>[Автор Бахтиярова Алина Шамильевна (Фамилия, И...</td>\n",
       "      <td>[автор бахтияров алина шамильевич фамилия имя ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/JM 505 Computers/Desktop/Repetitor/Ул...</td>\n",
       "      <td>Разработка VPN-приложения для мобильных устрой...</td>\n",
       "      <td>[Министерство науки и высшего образования Росс...</td>\n",
       "      <td>{'Министерство науки и высшего образования Рос...</td>\n",
       "      <td>[ФБИТ]</td>\n",
       "      <td>ФБИТ</td>\n",
       "      <td>ФБИТ</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>{'выпускная квалификационная работа': ['РАЗРАБ...</td>\n",
       "      <td>[РАЗРАБОТКА VPN-ПРИЛОЖЕНИЯ ДЛЯ МОБИЛЬНЫХ УСТРО...</td>\n",
       "      <td>[разработка vpnприложение для мобильный устрой...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/JM 505 Computers/Desktop/Repetitor/Ул...</td>\n",
       "      <td>Разработка автоматизированной системы защиты и...</td>\n",
       "      <td>[Министерство науки и высшего образования Росс...</td>\n",
       "      <td>{'Министерство науки и высшего образования Рос...</td>\n",
       "      <td>[ФБИТ]</td>\n",
       "      <td>ФБИТ</td>\n",
       "      <td>ФБИТ</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>{'разработка автоматизированной системы защиты...</td>\n",
       "      <td>[Автор Пенин Андрей Семенович, (Фамилия, Имя, ...</td>\n",
       "      <td>[автор пенина андрей семёнович, фамилия имя от...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path_doc  \\\n",
       "0  C:/Users/JM 505 Computers/Desktop/Repetitor/Ул...   \n",
       "1  C:/Users/JM 505 Computers/Desktop/Repetitor/Ул...   \n",
       "2  C:/Users/JM 505 Computers/Desktop/Repetitor/Ул...   \n",
       "3  C:/Users/JM 505 Computers/Desktop/Repetitor/Ул...   \n",
       "4  C:/Users/JM 505 Computers/Desktop/Repetitor/Ул...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Анализ методов обеспечения безопасной передачи...   \n",
       "1  Анализ психологических типов сотрудников для м...   \n",
       "2  Исследование влияния алгоритма стохастического...   \n",
       "3  Разработка VPN-приложения для мобильных устрой...   \n",
       "4  Разработка автоматизированной системы защиты и...   \n",
       "\n",
       "                                          text_paper  \\\n",
       "0  [ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА, АНАЛИЗ МЕТ...   \n",
       "1  [Министерство науки и высшего образования Росс...   \n",
       "2  [Министерство науки и высшего образования Росс...   \n",
       "3  [Министерство науки и высшего образования Росс...   \n",
       "4  [Министерство науки и высшего образования Росс...   \n",
       "\n",
       "                                 dict_sections_texts faculty_department  \\\n",
       "0  {'ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА': [], 'АНА...             [ФБИТ]   \n",
       "1  {'Министерство науки и высшего образования Рос...             [ФБИТ]   \n",
       "2  {'Министерство науки и высшего образования Рос...             [ФБИТ]   \n",
       "3  {'Министерство науки и высшего образования Рос...             [ФБИТ]   \n",
       "4  {'Министерство науки и высшего образования Рос...             [ФБИТ]   \n",
       "\n",
       "  faculty department    degree  \\\n",
       "0    ФБИТ       ФБИТ  bachelor   \n",
       "1    ФБИТ       ФБИТ  bachelor   \n",
       "2    ФБИТ       ФБИТ  bachelor   \n",
       "3    ФБИТ       ФБИТ  bachelor   \n",
       "4    ФБИТ       ФБИТ  bachelor   \n",
       "\n",
       "                           dict_sections_texts_clean  \\\n",
       "0  {'анализ методов обеспечения безопасной переда...   \n",
       "1  {'министерство науки и высшего образования рос...   \n",
       "2  {'исследование влияния алгоритма стохастическо...   \n",
       "3  {'выпускная квалификационная работа': ['РАЗРАБ...   \n",
       "4  {'разработка автоматизированной системы защиты...   \n",
       "\n",
       "                                     main_clean_text  \\\n",
       "0  [Автор Павлов Денис Дмитриевич, (Фамилия, Имя,...   \n",
       "1  [ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ АВТОНОМНОЕ ОБРАЗО...   \n",
       "2  [Автор Бахтиярова Алина Шамильевна (Фамилия, И...   \n",
       "3  [РАЗРАБОТКА VPN-ПРИЛОЖЕНИЯ ДЛЯ МОБИЛЬНЫХ УСТРО...   \n",
       "4  [Автор Пенин Андрей Семенович, (Фамилия, Имя, ...   \n",
       "\n",
       "                                        preproc_text  \n",
       "0  [автор павлов денис дмитриевич, фамилия имя от...  \n",
       "1  [федеральный государственный автономный образо...  \n",
       "2  [автор бахтияров алина шамильевич фамилия имя ...  \n",
       "3  [разработка vpnприложение для мобильный устрой...  \n",
       "4  [автор пенина андрей семёнович, фамилия имя от...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords = set(russian_stopwords + ['который', 'таблица', 'рисунок', \n",
    "                                             'тот', 'также', 'этот', 'это', \n",
    "                                             'такой', 'каждый', 'другой'])\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def sentences_preproc(lst_sentences):\n",
    "    lst_sentences_new = []\n",
    "    for sentence in list(lst_sentences):\n",
    "        sentence = ''.join([ch for ch in sentence if ch not in string.punctuation])\n",
    "        sentence = sentence.split()\n",
    "        \n",
    "        sentence_new = [morph.parse(word)[0].normal_form for word in sentence if word not in russian_stopwords and \\\n",
    "                    str(morph.parse(word)[0].tag) != 'UNKN']\n",
    "        \n",
    "        if len(sentence_new) > 1:\n",
    "            lst_sentences_new.append(' '.join(sentence_new))\n",
    "    return lst_sentences_new\n",
    "\n",
    "df_docs['preproc_text'] = df_docs['main_clean_text'].map(sentences_preproc)\n",
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs.to_csv('VKR_docs.csv', index = False)\n",
    "df_docs.to_excel('VKR_docs.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
